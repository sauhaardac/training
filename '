"""Training and validation code for bddmodelcar."""
import traceback
import logging

from Parameters import ARGS
import Data
import Batch
import Utils

import matplotlib.pyplot as plt

from nets.SqueezeNet import SqueezeNet
import torch


def main():
    logging.basicConfig(filename='training.log', level=logging.DEBUG)
    logging.debug(ARGS)  # Log arguments

    # Set Up PyTorch Environment
    # torch.set_default_tensor_type('torch.FloatTensor')
    torch.cuda.set_device(ARGS.gpu)
    torch.cuda.device(ARGS.gpu)

    nets = []

    net1 = {'net':SqueezeNet().cuda(), 'criterion':torch.nn.MSELoss().cuda()}
    net1['optimizer'] = torch.optim.Adadelta(net1['net'].parameters()

    net = SqueezeNet().cuda()
    criterion = torch.nn.MSELoss().cuda()
    optimizer = torch.optim.Adadelta(net.parameters())

    if ARGS.resume_path is not None:
        for resume_file in resume_path:
            print('Resuming w/ ' + ARGS.resume_path, 'yellow')
            save_data = torch.load(ARGS.resume_path)
            net.load_state_dict(save_data)

    data = Data.Data()
    batch = Batch.Batch(net)

    # Maitains a list of all inputs to the network, and the loss and outputs for
    # each of these runs. This can be used to sort the data by highest loss and
    # visualize, to do so run:
    # display_sort_trial_loss(data_moment_loss_record , data)
    data_moment_loss_record = {}
    rate_counter = Utils.RateCounter()

    def run_net(data_index):
        batch.fill(data, data_index)  # Get batches ready
        batch.forward(optimizer, criterion, data_moment_loss_record)

    try:
        epoch = 0
        avg_train_loss = Utils.LossLog()
        avg_val_loss = Utils.LossLog()
        net.eval()  # Evaluate mode
        while not data.val_index.epoch_complete:
            run_net(data.val_index)  # Run network

            if print_counter.step(data.val_index):
                print('mode = validation\n'
                      'ctr = {}\n'
                      'epoch progress = {} %\n'
                      .format(data.val_index.ctr,
                              100. * data.val_index.ctr /
                              len(data.val_index.valid_data_moments))

        
        data.val_index.epoch_complete = False
    except Exception:
        logging.error(traceback.format_exc())  # Log exception

        # Interrupt Saves
        Utils.save_net('interrupt_save', net)
        epoch_train_loss.export_csv(
            'logs/interrupt%02d_train_loss.csv' %
            (epoch,))
        epoch_val_loss.export_csv('logs/interrupt%02d_val_loss.csv' % (epoch,))


if __name__ == '__main__':
    main()
